{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import datetime\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import average_precision_score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we load the supermarket data from the 'supermarket_data.csv' file, split it into train and test sets and pivot the train set to create a user-item matrix, as well as calculating a user-user similarity matrix using the cosine similarity of the user-item matrix.\n",
        "\n",
        "We then define a function, 'collaborative_filtering', which is the function that will provide recommendations for our users, in this case one user. The function takes the target user's ID and the number of reccomendations to return as input parameters, and returns a list of tuples (3) which contain the recommended products and their predicted introduction score (as defined in the data creation ipynb). The function uses the similarity scores of the target user with other users (top n most similar users) also taking into account the products that the target user has not interacted with in order to calculate the interaction score for the uninteracted products. Finally, we print the sorted list of recommended products for the target user with ID 100 based on the predictions made by the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtf-5MaqC71c",
        "outputId": "264279d6-b1da-46f9-c27a-669c7c493f9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('kitchen utensil', 3.332519651665075), ('photo/film', 2.9975128198114396), ('curd', 2.6724547087120474)]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('supermarket_data.csv')\n",
        "\n",
        "train, test = train_test_split(df, test_size = 0.75, random_state = 42)\n",
        "\n",
        "matrix = train.pivot_table(index = 'User ID', columns = 'Product Name', values = 'Interaction Type', fill_value = 0)\n",
        "\n",
        "user_similarity = pd.DataFrame(cosine_similarity(matrix), index = matrix.index, columns = matrix.index)\n",
        "\n",
        "\n",
        "def collaborative_filtering(user_id, n_recommendations = 3):\n",
        "    \"\"\"\n",
        "    Collaborative filtering recommendation algorithm\n",
        "    \n",
        "    Parameters:\n",
        "    user_id (int): The ID of the target user\n",
        "    n_recommendations (int): The number of recommendations to return (default is 3)\n",
        "    \n",
        "    Returns:\n",
        "    A list of tuples containing the recommended products and their predicted interaction score\n",
        "    \"\"\"\n",
        "\n",
        "    sim_scores = user_similarity[user_id].sort_values(ascending = False)\n",
        "    \n",
        "    top_users = sim_scores.iloc[1:n_recommendations+1].index\n",
        "    \n",
        "    uninteracted_products = matrix.loc[user_id][matrix.loc[user_id] == 0].index\n",
        "    \n",
        "    interaction_scores = []\n",
        "    \n",
        "    for product in uninteracted_products:\n",
        "        interaction_score = np.average(matrix.loc[top_users][product], weights = sim_scores[top_users])\n",
        "        interaction_scores.append((product, interaction_score))\n",
        "    \n",
        "    sorted_scores = sorted(interaction_scores, key=lambda x: x[1], reverse = True)\n",
        "    \n",
        "    return sorted_scores[:n_recommendations]\n",
        "\n",
        "\n",
        "recommended_products = collaborative_filtering(user_id = 100, n_recommendations = 3)\n",
        "print(recommended_products)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we calculate the Mean Average Precision at k (MAP@k) score for a target user with ID 100. The code first generates recommendations for user_id 100 based on the 'collaborative_filtering' function, which we store in the 'recommended_products' variable. We then get the actual products that the user with ID 100 interacted with from the test data, which are stored in the 'actual_products' variable. Finally, the MAP@k score is calculated using the 'average_precision_score' function from Sklearn, where it is then printed, giving us an indiccation of the model's effectiveness. \n",
        "\n",
        "We have yet to fix a way of evaluating our model and comparing it to others, as can be seen from the poor output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['preservation products', 'mayonnaise', 'bathroom cleaner', 'butter milk', 'tidbits', 'liver loaf', 'candy', 'dog food', 'Instant food products', 'beef', 'dental care', 'pastry', 'ketchup', 'rice', 'frozen fish', 'specialty fat', 'frankfurter', 'house keeping products', 'curd cheese', 'frozen fruits', 'white bread', 'meat', 'soap', 'canned fish', 'spices', 'pudding powder', 'frozen potato products', 'nuts/prunes', 'cake bar', 'cream cheese ', 'sliced cheese', 'onions', 'liqueur', 'make up remover', 'softener', 'rum', 'male cosmetics', 'sausage', 'instant coffee', 'detergent', 'specialty bar', 'vinegar', 'frozen chicken', 'soups', 'domestic eggs', 'cling film/bags', 'frozen vegetables', 'kitchen towels', 'salty snack', 'bags', 'sparkling wine', 'hard cheese', 'pork', 'toilet cleaner', 'artif. sweetener', 'organic sausage', 'specialty cheese', 'cream', 'rubbing alcohol', 'shopping bags', 'meat spreads', 'chocolate', 'canned beer', 'pasta', 'popcorn', 'chicken', 'ham', 'sugar', 'dish cleaner', 'white wine', 'ice cream', 'tea', 'spread cheese', 'whipped/sour cream', 'flower soil/fertilizer', 'sweet spreads', 'honey', 'salt', 'semi-finished bread']\n",
            "['kitchen utensil', 'root vegetables', 'baking powder', 'misc. beverages', 'whole milk', 'frozen dessert', 'packaged fruit/vegetables', 'canned fruit', 'pet care', 'decalcifier']\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "MAP@3 score for user_id 100: -0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "recommended_products = collaborative_filtering(user_id = 100, n_recommendations = 10)\n",
        "\n",
        "\n",
        "actual_products = list(df.loc[df['User ID'] == 100]['Product Name'].unique())\n",
        "print(actual_products)\n",
        "\n",
        "k = 13\n",
        "recommended_k = list(p[0] for p in recommended_products[:k])\n",
        "print(recommended_k)\n",
        "\n",
        "y_true = [int(p in actual_products) for p in recommended_k]\n",
        "print(y_true)\n",
        "\n",
        "y_scores = [p[1] for p in recommended_products[:k]]\n",
        "average_precision = average_precision_score(y_true, y_scores)\n",
        "\n",
        "print(\"MAP@3 score for user_id 100:\", average_precision)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following is our new attemt to calculate MAP, NDCG, Precision@K, and Recall@K as was done with the SAR model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import average_precision_score, ndcg_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate(recommended_products, test_data, K):\n",
        "\n",
        "    relevant_products = test_data.groupby('User ID')['Product Name'].apply(list).reset_index(name = 'relevant')\n",
        "\n",
        "    MAP = average_precision_score(relevant_products['relevant'], [r[0] for r in recommended_products], average = 'macro')\n",
        "    NDCG = ndcg_score([relevant_products['relevant'].tolist()], [r[0] for r in recommended_products], k = K)\n",
        "\n",
        "    precision = []\n",
        "    recall = []\n",
        "    for user_id in relevant_products['User ID']:\n",
        "        relevant = set(relevant_products[relevant_products['User ID']==user_id]['relevant'].iloc[0])\n",
        "        recommended = set([r[0] for r in recommended_products if r[1]>=np.mean([r[1] for r in recommended_products])])\n",
        "        relevant_and_recommended = relevant.intersection(recommended)\n",
        "        precision.append(len(relevant_and_recommended)/K)\n",
        "        recall.append(len(relevant_and_recommended)/len(relevant))\n",
        "\n",
        "    Precision_at_K = np.mean(precision)\n",
        "    Recall_at_K = np.mean(recall)\n",
        "\n",
        "    return {'MAP': MAP, 'NDCG': NDCG, 'Precision@K': Precision_at_K, 'Recall@K': Recall_at_K}\n",
        "\n",
        "test_data = test[['User ID', 'Product Name', 'Interaction Type']]\n",
        "recommended_products = collaborative_filtering(user_id = 100, n_recommendations = 3)\n",
        "\n",
        "metrics = evaluate(recommended_products, test_data, K = 3)\n",
        "print(metrics)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
